{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Import our own file that has the feature extraction functions\n",
    "from extract_features import  process_images\n",
    "\n",
    "#-------------------\n",
    "# Main script\n",
    "#-------------------\n",
    "\n",
    "# Where is the raw data\n",
    "file_data = '..' + os.sep + 'data' + os.sep + 'metadata.csv'\n",
    "path_image = '..' + os.sep + 'data' + os.sep + 'images' + os.sep + 'images_original'\n",
    "path_mask = '..' + os.sep + 'data' + os.sep + 'images' + os.sep + 'masks_original'    \n",
    "\n",
    "# Where we will store the features\n",
    "file_features = 'features/features_original.csv'\n",
    "feature_names = ['assymetry', 'colours', 'dots and globules', 'compactness']\n",
    "\n",
    "df_features=process_images(file_data, path_image, path_mask,feature_names)\n",
    "# Save the image_id used + features to a file\n",
    "#df_features.to_excel(file_features, index=False)\n",
    "df_features.to_csv(file_features, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 1 (KNeighborsClassifier): average accuracy=0.819\n",
      "Classifier 2 (KNeighborsClassifier): average accuracy=0.889\n",
      "Classifier 3 (Pipeline): average accuracy=0.897\n",
      "Classifier 4 (RandomForestClassifier): average accuracy=0.866\n",
      "Classifier 5 (GradientBoostingClassifier): average accuracy=0.866\n",
      "Classifier 6 (AdaBoostClassifier): average accuracy=0.882\n",
      "Classifier 7 (DecisionTreeClassifier): average accuracy=0.819\n",
      "Classifier 8 (Pipeline): average accuracy=0.897\n",
      "Classifier 9 (Pipeline): average accuracy=0.812\n",
      "Classifier 10 (GaussianNB): average accuracy=0.842\n",
      "Classifier 11 (MLPClassifier): average accuracy=0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for KNeighborsClassifier:\n",
      "Accuracy: 0.8976377952755905\n",
      "Results for Pipeline:\n",
      "Accuracy: 0.8976377952755905\n",
      "Results for RandomForestClassifier:\n",
      "Accuracy: 0.968503937007874\n",
      "Results for GradientBoostingClassifier:\n",
      "Accuracy: 0.968503937007874\n",
      "Results for AdaBoostClassifier:\n",
      "Accuracy: 0.968503937007874\n",
      "Results for DecisionTreeClassifier:\n",
      "Accuracy: 0.968503937007874\n",
      "Results for GaussianNB:\n",
      "Accuracy: 0.8661417322834646\n",
      "Results for MLPClassifier:\n",
      "Accuracy: 0.8976377952755905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "metadata_df = pd.read_csv(file_data)\n",
    "combined_df = df_features.merge(metadata_df[['img_id', 'diagnostic', 'patient_id']], left_on='image_id', right_on='img_id', how='left')\n",
    "if combined_df.isnull().values.any():\n",
    "    raise ValueError(\"NaN values detected after merge! Check the data integrity.\")\n",
    "\n",
    "# Prepare the dataset\n",
    "X = combined_df[feature_names].to_numpy()\n",
    "y = combined_df['diagnostic'].values == 'NEV'  # NEV is assumed to be the healthy class\n",
    "patient_id = combined_df['patient_id'].values\n",
    "\n",
    "# Prepare cross-validation\n",
    "num_folds = 5\n",
    "group_kfold = GroupKFold(n_splits=num_folds)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(1),\n",
    "    KNeighborsClassifier(5),\n",
    "    make_pipeline(StandardScaler(), SVC(probability=True)),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)),\n",
    "    make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3)),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(max_iter=1000)\n",
    "]\n",
    "\n",
    "# Initialize accuracy storage\n",
    "acc_val = np.empty((num_folds, len(classifiers)))\n",
    "classifier_names = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for j, clf in enumerate(classifiers):\n",
    "    classifier_name = (clf.named_steps['svc'].__class__.__name__ if 'pipeline' in str(clf)\n",
    "                       else clf.__class__.__name__)\n",
    "    classifier_names.append(classifier_name)\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for i, (train_index, val_index) in enumerate(group_kfold.split(X, y, patient_id)):\n",
    "        x_train, y_train = X[train_index], y[train_index]\n",
    "        x_val, y_val = X[val_index], y[val_index]\n",
    "        \n",
    "        # Fit and predict\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        fold_accuracies.append(acc)\n",
    "        \n",
    "        # Save the classifier after training on this fold\n",
    "        fold_filename = f'classifier_{j}_fold_{i}.sav'\n",
    "        pickle.dump(clf, open(fold_filename, 'wb'))\n",
    "    \n",
    "    acc_val[:, j] = fold_accuracies\n",
    "\n",
    "# Calculate average accuracy for each classifier\n",
    "average_acc = np.mean(acc_val, axis=0)\n",
    "for idx, acc in enumerate(average_acc):\n",
    "    print(f'Classifier {idx + 1} ({classifier_names[idx]}): average accuracy={acc:.3f}')\n",
    "\n",
    "# Save and evaluate each classifier on the full dataset\n",
    "eval_results = {}\n",
    "for idx, clf in enumerate(classifiers):\n",
    "    classifier_name = classifier_names[idx]\n",
    "    classifier_filename = f'classifier_{idx}.sav'\n",
    "    \n",
    "    # Save the classifier\n",
    "    pickle.dump(clf, open(classifier_filename, 'wb'))\n",
    "    \n",
    "    # Load the classifier\n",
    "    loaded_clf = pickle.load(open(classifier_filename, 'rb'))\n",
    "    \n",
    "    # Predict on the full dataset and calculate evaluation metrics\n",
    "    y_pred = loaded_clf.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    clf_report = classification_report(y, y_pred)\n",
    "    \n",
    "    eval_results[classifier_name] = {'accuracy': acc, 'report': clf_report}\n",
    "\n",
    "# Display evaluation results\n",
    "for clf_name, results in eval_results.items():\n",
    "    print(f\"Results for {clf_name}:\")\n",
    "    print(f\"Accuracy: {results['accuracy']}\")\n",
    "    #print(f\"Classification Report:\\n{results['report']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import glob\n",
    "#features_path = 'features/features_evaluate.csv'\n",
    "file_data = '..' + os.sep + 'data' + os.sep + 'metadata.csv'\n",
    "path_image = '..' + os.sep + 'data' + os.sep + 'images' + os.sep + 'images_evaluate'\n",
    "path_mask = '..' + os.sep + 'data' + os.sep + 'images' + os.sep + 'masks_evaluate'    \n",
    "\n",
    "metadata_df = pd.read_csv(file_data)\n",
    "\n",
    "features_df = process_images(file_data, path_image, path_mask,feature_names)\n",
    "feature_names = ['assymetry', 'colours', 'dots and globules', 'compactness']\n",
    "\n",
    "# Merge features with metadata on 'image_id'/'img_id'\n",
    "combined_df = features_df.merge(metadata_df[['img_id', 'diagnostic', 'patient_id']], left_on='image_id', right_on='img_id', how='left')\n",
    "\n",
    "# Prepare the dataset\n",
    "X = combined_df[feature_names].to_numpy()\n",
    "y = combined_df['diagnostic'] == 'NEV'  # NEV is assumed to be the healthy class\n",
    "patient_id = combined_df['patient_id']\n",
    "\n",
    "# Function to load a classifier and evaluate it\n",
    "def load_and_evaluate(model_filename, X, y):\n",
    "    try:\n",
    "        with open(model_filename, 'rb') as model_file:\n",
    "            classifier = pickle.load(model_file)\n",
    "        print(f\"Loaded classifier from {model_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the model from {model_filename}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Predict the labels and calculate accuracy and confusion matrix\n",
    "    pred_labels = classifier.predict(X)\n",
    "    accuracy = accuracy_score(y, pred_labels)\n",
    "    cm = confusion_matrix(y, pred_labels)\n",
    "    \n",
    "    return accuracy, cm\n",
    "\n",
    "# List of classifier filenames\n",
    "#classifier_filenames = [f'classifier_{i}.sav' for i in range(len(os.listdir(r\"C:\\Users\\tettret\\OneDrive - DFDS\\Desktop\\ITU\\Data Science Project\\Project_data_science_queen_snakes-3\\Classifier\\fyp2024\")))]\n",
    "classifier_filenames = glob.glob(os.path.join('..', '*.sav'))\n",
    "# Evaluate all classifiers\n",
    "for model_filename in classifier_filenames:\n",
    "    accuracy, cm = load_and_evaluate(model_filename, X, y)\n",
    "    print(f\"Results for {model_filename}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
