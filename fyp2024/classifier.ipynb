{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge metadata and annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image_id</th>\n",
       "      <th>Annotator ID 1</th>\n",
       "      <th>Annotator ID 2</th>\n",
       "      <th>Annotator ID 3</th>\n",
       "      <th>Asymmetry 1</th>\n",
       "      <th>Asymmetry 2</th>\n",
       "      <th>Asymmetry 3</th>\n",
       "      <th>Color 1</th>\n",
       "      <th>Color 2</th>\n",
       "      <th>...</th>\n",
       "      <th>Dots and globules 1</th>\n",
       "      <th>Dots and globules 2</th>\n",
       "      <th>Dots and globules 3</th>\n",
       "      <th>img_id_cleaned</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>img_id</th>\n",
       "      <th>image name</th>\n",
       "      <th>green circle found</th>\n",
       "      <th>dots and globules 1</th>\n",
       "      <th>dots and globules 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PAT_1180_650_843_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1180_650_843</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_1180_650_843.png</td>\n",
       "      <td>PAT_1180_650_843.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAT_1185_679_115_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1185_679_115</td>\n",
       "      <td>SEK</td>\n",
       "      <td>PAT_1185_679_115.png</td>\n",
       "      <td>PAT_1185_679_115.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PAT_1202_722_827_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PAT_1202_722_827</td>\n",
       "      <td>SEK</td>\n",
       "      <td>PAT_1202_722_827.png</td>\n",
       "      <td>PAT_1202_722_827.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PAT_1260_894_63_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1260_894_63</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_1260_894_63.png</td>\n",
       "      <td>PAT_1260_894_63.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PAT_1303_1077_501_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1303_1077_501</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_1303_1077_501.png</td>\n",
       "      <td>PAT_1303_1077_501.png.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>PAT_388_4500_103_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_388_4500_103</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_388_4500_103.png</td>\n",
       "      <td>PAT_388_4500_103.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>PAT_404_805_575_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_404_805_575</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_404_805_575.png</td>\n",
       "      <td>PAT_404_805_575.png.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>PAT_406_1542_754_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_406_1542_754</td>\n",
       "      <td>BCC</td>\n",
       "      <td>PAT_406_1542_754.png</td>\n",
       "      <td>PAT_406_1542_754.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>PAT_406_808_560_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_406_808_560</td>\n",
       "      <td>BCC</td>\n",
       "      <td>PAT_406_808_560.png</td>\n",
       "      <td>PAT_406_808_560.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>PAT_409_2614_24_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_409_2614_24</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_409_2614_24.png</td>\n",
       "      <td>PAT_409_2614_24.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                        Image_id Annotator ID 1 Annotator ID 2  \\\n",
       "0             0   PAT_1180_650_843_mask.png.jpg             q1            NaN   \n",
       "1             1   PAT_1185_679_115_mask.png.jpg             q1            NaN   \n",
       "2             2   PAT_1202_722_827_mask.png.jpg             q1            NaN   \n",
       "3             3    PAT_1260_894_63_mask.png.jpg             q1            NaN   \n",
       "4             4  PAT_1303_1077_501_mask.png.jpg             q1            NaN   \n",
       "..          ...                             ...            ...            ...   \n",
       "122         122   PAT_388_4500_103_mask.png.jpg             q3             q2   \n",
       "123         123    PAT_404_805_575_mask.png.jpg             q3             q2   \n",
       "124         124   PAT_406_1542_754_mask.png.jpg             q3             q2   \n",
       "125         125    PAT_406_808_560_mask.png.jpg             q3             q2   \n",
       "126         126    PAT_409_2614_24_mask.png.jpg             q3             q2   \n",
       "\n",
       "    Annotator ID 3  Asymmetry 1  Asymmetry 2  Asymmetry 3  Color 1  Color 2  \\\n",
       "0               q4          2.0          NaN          0.0      3.0      NaN   \n",
       "1               q4          1.0          NaN          1.0      3.0      NaN   \n",
       "2               q4          2.0          NaN          1.0      2.0      NaN   \n",
       "3               q4          2.0          NaN          1.0      2.0      NaN   \n",
       "4               q4          2.0          NaN          0.0      3.0      NaN   \n",
       "..             ...          ...          ...          ...      ...      ...   \n",
       "122            NaN          2.0          2.0          NaN      2.0      2.0   \n",
       "123            NaN          1.0          1.0          NaN      2.0      3.0   \n",
       "124            NaN          0.0          0.0          NaN      4.0      4.0   \n",
       "125            NaN          1.0          0.0          NaN      3.0      4.0   \n",
       "126            NaN          1.0          2.0          NaN      2.0      2.0   \n",
       "\n",
       "     ...  Dots and globules 1  Dots and globules 2  Dots and globules 3  \\\n",
       "0    ...                  0.0                  NaN                  0.0   \n",
       "1    ...                  0.0                  NaN                  0.0   \n",
       "2    ...                  1.0                  NaN                  1.0   \n",
       "3    ...                  0.0                  NaN                  0.0   \n",
       "4    ...                  0.0                  NaN                  0.0   \n",
       "..   ...                  ...                  ...                  ...   \n",
       "122  ...                  0.0                  0.0                  NaN   \n",
       "123  ...                  1.0                  1.0                  NaN   \n",
       "124  ...                  1.0                  1.0                  NaN   \n",
       "125  ...                  1.0                  1.0                  NaN   \n",
       "126  ...                  0.0                  0.0                  NaN   \n",
       "\n",
       "        img_id_cleaned diagnostic                 img_id  \\\n",
       "0     PAT_1180_650_843        ACK   PAT_1180_650_843.png   \n",
       "1     PAT_1185_679_115        SEK   PAT_1185_679_115.png   \n",
       "2     PAT_1202_722_827        SEK   PAT_1202_722_827.png   \n",
       "3      PAT_1260_894_63        ACK    PAT_1260_894_63.png   \n",
       "4    PAT_1303_1077_501        ACK  PAT_1303_1077_501.png   \n",
       "..                 ...        ...                    ...   \n",
       "122   PAT_388_4500_103        ACK   PAT_388_4500_103.png   \n",
       "123    PAT_404_805_575        ACK    PAT_404_805_575.png   \n",
       "124   PAT_406_1542_754        BCC   PAT_406_1542_754.png   \n",
       "125    PAT_406_808_560        BCC    PAT_406_808_560.png   \n",
       "126    PAT_409_2614_24        ACK    PAT_409_2614_24.png   \n",
       "\n",
       "                    image name green circle found  dots and globules 1  \\\n",
       "0     PAT_1180_650_843.png.jpg                  1                    0   \n",
       "1     PAT_1185_679_115.png.jpg                  1                    1   \n",
       "2     PAT_1202_722_827.png.jpg                  1                    1   \n",
       "3      PAT_1260_894_63.png.jpg                  1                    0   \n",
       "4    PAT_1303_1077_501.png.jpg                  0                    0   \n",
       "..                         ...                ...                  ...   \n",
       "122   PAT_388_4500_103.png.jpg                  1                    0   \n",
       "123    PAT_404_805_575.png.jpg                  0                    0   \n",
       "124   PAT_406_1542_754.png.jpg                  1                    1   \n",
       "125    PAT_406_808_560.png.jpg                  1                    1   \n",
       "126    PAT_409_2614_24.png.jpg                  1                    0   \n",
       "\n",
       "     dots and globules 2  \n",
       "0                    0.0  \n",
       "1                    1.0  \n",
       "2                    1.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "..                   ...  \n",
       "122                  0.0  \n",
       "123                  0.0  \n",
       "124                  1.0  \n",
       "125                  1.0  \n",
       "126                  0.0  \n",
       "\n",
       "[127 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "metadata_filename='..' + os.sep + 'data' + os.sep +'metadata.csv'\n",
    "metadata=pd.read_csv(metadata_filename)\n",
    "\n",
    "annotations=pd.read_excel(r\"C:\\Users\\tettret\\OneDrive - DFDS\\Desktop\\ITU\\Data Science Project\\Classifier\\Queen_snakes_imageids_new.xlsx\")\n",
    "dots=pd.read_excel(r\"C:\\Users\\tettret\\OneDrive - DFDS\\Desktop\\ITU\\Data Science Project\\Classifier\\dots_merged.xlsx\")\n",
    "dots['img_id_cleaned']=dots['image name'].str.split('.').str[0]\n",
    "metadata['img_id_cleaned']=metadata['img_id'].str.split('.').str[0]\n",
    "annotations['img_id_cleaned']=annotations['Image_id'].str.split('.').str[0]\n",
    "annotations['img_id_cleaned'] = annotations['img_id_cleaned'].str.replace('_mask', '')\n",
    "\n",
    "\n",
    "annotations_metadata=pd.merge(annotations,metadata[['diagnostic','img_id','img_id_cleaned']], on='img_id_cleaned', how=\"left\")\n",
    "annotations_metadata_dots=pd.merge(annotations_metadata,dots, on=\"img_id_cleaned\", how=\"left\")\n",
    "annotations_metadata_dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Import our own file that has the feature extraction functions\n",
    "from extract_features import extract_features\n",
    "\n",
    "\n",
    "\n",
    "#-------------------\n",
    "# Main script\n",
    "#-------------------\n",
    "\n",
    "\n",
    "#Where is the raw data\n",
    "file_data = '..' + os.sep + 'data' + os.sep +'metadata.csv'\n",
    "path_image = '..' + os.sep + 'data' + os.sep + 'images' + os.sep + 'imgs_part_1'\n",
    "path_mask = '..' + os.sep + 'data' + os.sep + 'images' + os.sep + 'Queen_snakes_masks'    \n",
    "  \n",
    "#Where we will store the features\n",
    "file_features = 'features/features.csv'\n",
    "\n",
    "\n",
    "#Read meta-data into a Pandas dataframe\n",
    "df = pd.read_csv(file_data)\n",
    "\n",
    "# Extract image IDs and labels from the data. \n",
    "#image_id = list(df['img_id'])\n",
    "image_id = [id + \".jpg\" for id in df['img_id']]\n",
    "mask_id = [id.replace('.png', '_mask.png') + '.jpg' for id in df['img_id']]\n",
    "label = np.array(df['diagnostic'])\n",
    "\n",
    "# Here you could decide to filter the data in some way (see task 0)\n",
    "# For example you can have a file selected_images.csv which stores the IDs of the files you need\n",
    "is_nevus =  label == 'NEV'\n",
    "\n",
    "num_images = len(image_id)\n",
    "\n",
    "\n",
    "#Make array to store features\n",
    "feature_names = ['assymetry','colours','dots and globules']\n",
    "num_features = len(feature_names)\n",
    "features = np.zeros([num_images,num_features], dtype=np.float16)  \n",
    "\n",
    "\n",
    "#Loop through all images (now just 10 for demonstration)\n",
    "for i in np.arange(num_images):\n",
    "    \n",
    "    # Define filenames related to this image\n",
    "    file_image = path_image + os.sep + image_id[i] \n",
    "    file_image_mask = path_mask + os.sep + df['img_id'][i].replace('.png', '_mask.png') + '.jpg' \n",
    "    \n",
    "    if exists(file_image):\n",
    "        \n",
    "        if exists(file_image_mask):\n",
    "        # Read the image\n",
    "            im = cv2.imread(file_image)\n",
    "            mask=cv2.imread(file_image_mask, cv2.IMREAD_GRAYSCALE)\n",
    "            #im = np.float16(im)  \n",
    "            #mask = np.float16(mask)  \n",
    "            # Measure features - this does not do anything useful yet!\n",
    "            x = extract_features(im,mask) \n",
    "            \n",
    "            # Store in the variable we created before\n",
    "            features[i,:] = x\n",
    "       \n",
    "        \n",
    "#Save the image_id used + features to a file   \n",
    "df_features = pd.DataFrame(features, columns=feature_names)     \n",
    "df_features.to_csv(file_features, index=False)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Import our own file that has the feature extraction functions\n",
    "from extract_features import extract_features\n",
    "\n",
    "#-------------------\n",
    "# Main script\n",
    "#-------------------\n",
    "\n",
    "# Where is the raw data\n",
    "file_data = '..' + os.sep + 'data' + os.sep + 'metadata.csv'\n",
    "path_image = '..' + os.sep + 'data' + os.sep + 'images' + os.sep + 'images_evaluate'\n",
    "path_mask = '..' + os.sep + 'data' + os.sep + 'images' + os.sep + 'masks_evaluate'    \n",
    "\n",
    "# Where we will store the features\n",
    "file_features = 'features/features_evaluate.csv'\n",
    "\n",
    "# Read meta-data into a Pandas dataframe\n",
    "df = pd.read_csv(file_data)\n",
    "\n",
    "# Extract image IDs and labels from the data.\n",
    "#image_id = [id + \".jpg\" for id in df['img_id']]\n",
    "image_id =  list(df['img_id'])\n",
    "#mask_id = [id.replace('.png', '_mask.png') + '.jpg' for id in df['img_id']]\n",
    "mask_id = [id.replace('.png', '_mask.png') for id in df['img_id']]\n",
    "label = np.array(df['diagnostic'])\n",
    "\n",
    "# Make array to store features and list for valid image IDs\n",
    "feature_names = ['assymetry', 'colours', 'dots and globules', 'compactness']\n",
    "num_features = len(feature_names)\n",
    "features = []\n",
    "valid_image_ids = []\n",
    "\n",
    "# Loop through all images (limited by num_images)\n",
    "num_images = len(image_id)\n",
    "for i in np.arange(num_images):\n",
    "    # Define filenames related to this image\n",
    "    file_image = path_image + os.sep + image_id[i]\n",
    "    file_image_mask = path_mask + os.sep + mask_id[i]\n",
    "\n",
    "    # Check if both the image and mask files exist\n",
    "    if exists(file_image) and exists(file_image_mask):\n",
    "        # Read the image and mask\n",
    "        im = cv2.imread(file_image)\n",
    "        mask = cv2.imread(file_image_mask, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Measure features\n",
    "        x = extract_features(im, mask)\n",
    "\n",
    "        # Store in the list we created before\n",
    "        features.append(x)\n",
    "\n",
    "        # Keep track of the valid image ID\n",
    "        valid_image_ids.append(image_id[i])\n",
    "\n",
    "# Create DataFrame from the features list and add image IDs\n",
    "df_features = pd.DataFrame(features, columns=feature_names)\n",
    "df_features['image_id'] = valid_image_ids\n",
    "\n",
    "# Save the image_id used + features to a file\n",
    "#df_features.to_excel(file_features, index=False)\n",
    "df_features.to_csv(file_features, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [127, 2298, 2298]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 50\u001b[0m\n\u001b[0;32m     45\u001b[0m num_classifiers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(classifiers)\n\u001b[0;32m     48\u001b[0m acc_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty([num_folds,num_classifiers])\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index, val_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(group_kfold\u001b[38;5;241m.\u001b[39msplit(x, y, patient_id)):\n\u001b[0;32m     52\u001b[0m     x_train \u001b[38;5;241m=\u001b[39m x[train_index,:]\n\u001b[0;32m     53\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m y[train_index]\n",
      "File \u001b[1;32mc:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:367\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m        The testing set indices for that split.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    368\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n",
      "File \u001b[1;32mc:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m check_consistent_length(\u001b[38;5;241m*\u001b[39mresult)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [127, 2298, 2298]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Default packages for the minimum example\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score #example for measuring performance\n",
    "\n",
    "\n",
    "import pickle #for saving/loading trained classifiers\n",
    "\n",
    "\n",
    "#Where are the files\n",
    "file_data = '..' + os.sep + 'data' + os.sep +'metadata.csv'\n",
    "df = pd.read_csv(file_data)\n",
    "label = np.array(df['diagnostic'])\n",
    "\n",
    "\n",
    "#Where did we store the features?\n",
    "file_features = 'features/features.csv'\n",
    "feature_names = ['assymetry', 'colours', 'dots and globules', 'compactness']\n",
    "\n",
    "# Load the features - remember the example features are not informative\n",
    "df_features = pd.read_csv(file_features)\n",
    "\n",
    "\n",
    "# Make the dataset, you can select different classes (see task 0)\n",
    "x = np.array(df_features[feature_names])\n",
    "y =  label == 'NEV'   #now True means healthy nevus, False means something else\n",
    "patient_id = df['patient_id']\n",
    "\n",
    "\n",
    "#Prepare cross-validation - images from the same patient must always stay together\n",
    "num_folds = 5\n",
    "group_kfold = GroupKFold(n_splits=num_folds)\n",
    "group_kfold.get_n_splits(x, y, patient_id)\n",
    "\n",
    "\n",
    "#Different classifiers to test out\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(1),\n",
    "    KNeighborsClassifier(5)\n",
    "]\n",
    "num_classifiers = len(classifiers)\n",
    "\n",
    "      \n",
    "acc_val = np.empty([num_folds,num_classifiers])\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(group_kfold.split(x, y, patient_id)):\n",
    "    \n",
    "    x_train = x[train_index,:]\n",
    "    y_train = y[train_index]\n",
    "    x_val = x[val_index,:]\n",
    "    y_val = y[val_index]\n",
    "    \n",
    "    \n",
    "    for j, clf in enumerate(classifiers): \n",
    "        \n",
    "        #Train the classifier\n",
    "        clf.fit(x_train,y_train)\n",
    "    \n",
    "        #Evaluate your metric of choice (accuracy is probably not the best choice)\n",
    "        acc_val[i,j] = accuracy_score(y_val, clf.predict(x_val))\n",
    "   \n",
    "    \n",
    "#Average over all folds\n",
    "average_acc = np.mean(acc_val,axis=0) \n",
    "   \n",
    "print('Classifier 1 average accuracy={:.3f} '.format(average_acc[0]))\n",
    "print('Classifier 2 average accuracy={:.3f} '.format(average_acc[1]))\n",
    "\n",
    "\n",
    "\n",
    "#Let's say you now decided to use the 5-NN \n",
    "classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "#It will be tested on external data, so we can try to maximize the use of our available data by training on \n",
    "#ALL of x and y\n",
    "classifier = classifier.fit(x,y)\n",
    "\n",
    "#This is the classifier you need to save using pickle, add this to your zip file submission\n",
    "filename = 'groupXY_classifier.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 1 average accuracy=0.810\n",
      "Classifier 2 average accuracy=0.897\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load the metadata and features data\n",
    "metadata_path =  '..' + os.sep + 'data' + os.sep +'metadata.csv'\n",
    "features_path = 'features/features.csv'\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "features_df = pd.read_csv(features_path)\n",
    "feature_names = ['colours', 'dots and globules', 'compactness']\n",
    "\n",
    "# Correct the 'image_id' in features to match 'img_id' in metadata\n",
    "features_df['image_id'] = features_df['image_id'].str.replace('.png.jpg', '.png')\n",
    "\n",
    "# Merge features with metadata on 'image_id'/'img_id'\n",
    "combined_df = features_df.merge(metadata_df[['img_id', 'diagnostic','patient_id']], left_on='image_id', right_on='img_id', how='left')\n",
    "\n",
    "# Prepare the dataset\n",
    "feature_columns = combined_df.columns[:-2]  # Exclude 'image_id' and 'img_id' columns\n",
    "X = combined_df[feature_names].to_numpy()\n",
    "y = combined_df['diagnostic'] == 'NEV'  # True for 'NEV', False otherwise\n",
    "patient_id = combined_df['patient_id']\n",
    "\n",
    "# Prepare cross-validation\n",
    "num_folds = 5\n",
    "group_kfold = GroupKFold(n_splits=num_folds)\n",
    "group_kfold.get_n_splits(X, y, patient_id)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(1),\n",
    "    KNeighborsClassifier(5)\n",
    "]\n",
    "\n",
    "# Initialize accuracy storage\n",
    "acc_val = np.empty([num_folds, len(classifiers)])\n",
    "\n",
    "# Perform cross-validation\n",
    "for i, (train_index, val_index) in enumerate(group_kfold.split(X, y, patient_id)):\n",
    "    x_train, y_train = X[train_index], y[train_index]\n",
    "    x_val, y_val = X[val_index], y[val_index]\n",
    "    \n",
    "    for j, clf in enumerate(classifiers):\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        acc_val[i, j] = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Calculate average accuracy\n",
    "average_acc = np.mean(acc_val, axis=0)\n",
    "print(f'Classifier 1 average accuracy={average_acc[0]:.3f}')\n",
    "print(f'Classifier 2 average accuracy={average_acc[1]:.3f}')\n",
    "\n",
    "# Select the classifier and train on all data\n",
    "best_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "best_classifier.fit(X, y)\n",
    "\n",
    "# Save the classifier\n",
    "filename = 'groupXY_classifier.sav'\n",
    "pickle.dump(best_classifier, open(filename, 'wb'))\n",
    "\n",
    "# Correct file paths if needed when running this script in your local environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 1 (KNeighborsClassifier): average accuracy=0.819\n",
      "Classifier 2 (KNeighborsClassifier): average accuracy=0.889\n",
      "Classifier 3 (Pipeline): average accuracy=0.897\n",
      "Classifier 4 (RandomForestClassifier): average accuracy=0.866\n",
      "Classifier 5 (GradientBoostingClassifier): average accuracy=0.866\n",
      "Classifier 6 (AdaBoostClassifier): average accuracy=0.889\n",
      "Classifier 7 (DecisionTreeClassifier): average accuracy=0.819\n",
      "Classifier 8 (LogisticRegression): average accuracy=0.897\n",
      "Classifier 9 (SGDClassifier): average accuracy=0.828\n",
      "Classifier 10 (GaussianNB): average accuracy=0.842\n",
      "Classifier 11 (MLPClassifier): average accuracy=0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Load the metadata and features data\n",
    "metadata_path = '..' + os.sep + 'data' + os.sep + 'metadata.csv'\n",
    "features_path = 'features/features.csv'\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "features_df = pd.read_csv(features_path)\n",
    "feature_names = ['assymetry', 'colours', 'dots and globules', 'compactness']\n",
    "\n",
    "# Correct the 'image_id' in features to match 'img_id' in metadata\n",
    "features_df['image_id'] = features_df['image_id'].str.replace('.png.jpg', '.png')\n",
    "\n",
    "# Merge features with metadata on 'image_id'/'img_id'\n",
    "combined_df = features_df.merge(metadata_df[['img_id', 'diagnostic', 'patient_id']], left_on='image_id', right_on='img_id', how='left')\n",
    "\n",
    "# Prepare the dataset\n",
    "X = combined_df[feature_names].to_numpy()\n",
    "y = combined_df['diagnostic'] == 'NEV'\n",
    "patient_id = combined_df['patient_id']\n",
    "\n",
    "# Prepare cross-validation\n",
    "num_folds = 5\n",
    "group_kfold = GroupKFold(n_splits=num_folds)\n",
    "group_kfold.get_n_splits(X, y, patient_id)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(1),\n",
    "    KNeighborsClassifier(5),\n",
    "    make_pipeline(StandardScaler(), SVC(probability=True)),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    SGDClassifier(max_iter=1000, tol=1e-3),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(max_iter=1000)\n",
    "]\n",
    "\n",
    "# Initialize accuracy storage\n",
    "acc_val = np.empty((num_folds, len(classifiers)))\n",
    "\n",
    "# Perform cross-validation\n",
    "for i, (train_index, val_index) in enumerate(group_kfold.split(X, y, patient_id)):\n",
    "    x_train, y_train = X[train_index], y[train_index]\n",
    "    x_val, y_val = X[val_index], y[val_index]\n",
    "    \n",
    "    for j, clf in enumerate(classifiers):\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        acc_val[i, j] = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Calculate average accuracy for each classifier\n",
    "average_acc = np.mean(acc_val, axis=0)\n",
    "for idx, clf in enumerate(classifiers):\n",
    "    print(f'Classifier {idx + 1} ({clf.__class__.__name__}): average accuracy={average_acc[idx]:.3f}')\n",
    "\n",
    "# Select the best classifier and train on all data\n",
    "best_index = np.argmax(average_acc)\n",
    "best_classifier = classifiers[best_index]\n",
    "best_classifier.fit(X, y)\n",
    "\n",
    "# Save the best classifier\n",
    "filename = 'best_classifier.sav'\n",
    "pickle.dump(best_classifier, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 1 (KNeighborsClassifier): average accuracy=0.819\n",
      "Classifier 2 (KNeighborsClassifier): average accuracy=0.889\n",
      "Classifier 3 (Pipeline): average accuracy=0.897\n",
      "Classifier 4 (RandomForestClassifier): average accuracy=0.866\n",
      "Classifier 5 (GradientBoostingClassifier): average accuracy=0.866\n",
      "Classifier 6 (AdaBoostClassifier): average accuracy=0.889\n",
      "Classifier 7 (DecisionTreeClassifier): average accuracy=0.819\n",
      "Classifier 8 (Pipeline): average accuracy=0.897\n",
      "Classifier 9 (Pipeline): average accuracy=0.780\n",
      "Classifier 10 (GaussianNB): average accuracy=0.842\n",
      "Classifier 11 (MLPClassifier): average accuracy=0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for KNeighborsClassifier:\n",
      "Accuracy: 0.8976377952755905\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      1.00      0.95       114\n",
      "        True       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.90       127\n",
      "   macro avg       0.45      0.50      0.47       127\n",
      "weighted avg       0.81      0.90      0.85       127\n",
      "\n",
      "\n",
      "Results for Pipeline:\n",
      "Accuracy: 0.8976377952755905\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      1.00      0.95       114\n",
      "        True       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.90       127\n",
      "   macro avg       0.45      0.50      0.47       127\n",
      "weighted avg       0.81      0.90      0.85       127\n",
      "\n",
      "\n",
      "Results for RandomForestClassifier:\n",
      "Accuracy: 0.968503937007874\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      1.00      0.98       114\n",
      "        True       1.00      0.69      0.82        13\n",
      "\n",
      "    accuracy                           0.97       127\n",
      "   macro avg       0.98      0.85      0.90       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n",
      "\n",
      "Results for GradientBoostingClassifier:\n",
      "Accuracy: 0.968503937007874\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      1.00      0.98       114\n",
      "        True       1.00      0.69      0.82        13\n",
      "\n",
      "    accuracy                           0.97       127\n",
      "   macro avg       0.98      0.85      0.90       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n",
      "\n",
      "Results for AdaBoostClassifier:\n",
      "Accuracy: 0.968503937007874\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      1.00      0.98       114\n",
      "        True       1.00      0.69      0.82        13\n",
      "\n",
      "    accuracy                           0.97       127\n",
      "   macro avg       0.98      0.85      0.90       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n",
      "\n",
      "Results for DecisionTreeClassifier:\n",
      "Accuracy: 0.968503937007874\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.97      0.98       114\n",
      "        True       0.80      0.92      0.86        13\n",
      "\n",
      "    accuracy                           0.97       127\n",
      "   macro avg       0.90      0.95      0.92       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n",
      "\n",
      "Results for GaussianNB:\n",
      "Accuracy: 0.8661417322834646\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.96      0.93       114\n",
      "        True       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.87       127\n",
      "   macro avg       0.45      0.48      0.46       127\n",
      "weighted avg       0.80      0.87      0.83       127\n",
      "\n",
      "\n",
      "Results for MLPClassifier:\n",
      "Accuracy: 0.8976377952755905\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      1.00      0.95       114\n",
      "        True       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.90       127\n",
      "   macro avg       0.45      0.50      0.47       127\n",
      "weighted avg       0.81      0.90      0.85       127\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Load the metadata and features data\n",
    "metadata_path = '..' + os.sep + 'data' + os.sep + 'metadata.csv'\n",
    "features_path = 'features' + os.sep + 'features.csv'\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "features_df = pd.read_csv(features_path)\n",
    "feature_names = ['assymetry', 'colours', 'dots and globules', 'compactness']\n",
    "\n",
    "# Correct the 'image_id' in features to match 'img_id' in metadata\n",
    "features_df['image_id'] = features_df['image_id'].str.replace('.png.jpg', '.png', regex=False)\n",
    "\n",
    "# Merge features with metadata on 'image_id'/'img_id'\n",
    "combined_df = features_df.merge(metadata_df[['img_id', 'diagnostic', 'patient_id']], left_on='image_id', right_on='img_id', how='left')\n",
    "\n",
    "# Check for any NaNs after the merge and handle them before proceeding.\n",
    "if combined_df.isnull().values.any():\n",
    "    raise ValueError(\"NaN values detected after merge! Check the data integrity.\")\n",
    "\n",
    "# Prepare the dataset\n",
    "X = combined_df[feature_names].to_numpy()\n",
    "y = combined_df['diagnostic'].values == 'NEV'  # NEV is assumed to be the healthy class\n",
    "patient_id = combined_df['patient_id'].values\n",
    "\n",
    "# Prepare cross-validation\n",
    "num_folds = 5\n",
    "group_kfold = GroupKFold(n_splits=num_folds)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(1),\n",
    "    KNeighborsClassifier(5),\n",
    "    make_pipeline(StandardScaler(), SVC(probability=True)),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)),\n",
    "    make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3)),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(max_iter=1000)\n",
    "]\n",
    "\n",
    "# Initialize accuracy storage\n",
    "acc_val = np.empty((num_folds, len(classifiers)))\n",
    "classifier_names = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for j, clf in enumerate(classifiers):\n",
    "    classifier_name = (clf.named_steps['svc'].__class__.__name__ if 'pipeline' in str(clf)\n",
    "                       else clf.__class__.__name__)\n",
    "    classifier_names.append(classifier_name)\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for i, (train_index, val_index) in enumerate(group_kfold.split(X, y, patient_id)):\n",
    "        x_train, y_train = X[train_index], y[train_index]\n",
    "        x_val, y_val = X[val_index], y[val_index]\n",
    "        \n",
    "        # Fit and predict\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        fold_accuracies.append(acc)\n",
    "        \n",
    "        # Save the classifier after training on this fold\n",
    "        fold_filename = f'classifier_{j}_fold_{i}.sav'\n",
    "        pickle.dump(clf, open(fold_filename, 'wb'))\n",
    "    \n",
    "    acc_val[:, j] = fold_accuracies\n",
    "\n",
    "# Calculate average accuracy for each classifier\n",
    "average_acc = np.mean(acc_val, axis=0)\n",
    "for idx, acc in enumerate(average_acc):\n",
    "    print(f'Classifier {idx + 1} ({classifier_names[idx]}): average accuracy={acc:.3f}')\n",
    "\n",
    "# Save and evaluate each classifier on the full dataset\n",
    "eval_results = {}\n",
    "for idx, clf in enumerate(classifiers):\n",
    "    classifier_name = classifier_names[idx]\n",
    "    classifier_filename = f'classifier_{idx}.sav'\n",
    "    \n",
    "    # Save the classifier\n",
    "    pickle.dump(clf, open(classifier_filename, 'wb'))\n",
    "    \n",
    "    # Load the classifier\n",
    "    loaded_clf = pickle.load(open(classifier_filename, 'rb'))\n",
    "    \n",
    "    # Predict on the full dataset and calculate evaluation metrics\n",
    "    y_pred = loaded_clf.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    clf_report = classification_report(y, y_pred)\n",
    "    \n",
    "    eval_results[classifier_name] = {'accuracy': acc, 'report': clf_report}\n",
    "\n",
    "# Display evaluation results\n",
    "for clf_name, results in eval_results.items():\n",
    "    print(f\"Results for {clf_name}:\")\n",
    "    print(f\"Accuracy: {results['accuracy']}\")\n",
    "    print(f\"Classification Report:\\n{results['report']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 1 (KNeighborsClassifier): average accuracy=0.819\n",
      "Classifier 2 (KNeighborsClassifier): average accuracy=0.889\n",
      "Classifier 3 (Pipeline): average accuracy=0.897\n",
      "Classifier 4 (RandomForestClassifier): average accuracy=0.866\n",
      "Classifier 5 (GradientBoostingClassifier): average accuracy=0.866\n",
      "Classifier 6 (AdaBoostClassifier): average accuracy=0.889\n",
      "Classifier 7 (DecisionTreeClassifier): average accuracy=0.819\n",
      "Classifier 8 (Pipeline): average accuracy=0.897\n",
      "Classifier 9 (Pipeline): average accuracy=0.850\n",
      "Classifier 10 (GaussianNB): average accuracy=0.842\n",
      "Classifier 11 (MLPClassifier): average accuracy=0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tettret\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Load the metadata and features data\n",
    "metadata_path = '..' + os.sep + 'data' + os.sep + 'metadata.csv'\n",
    "features_path = 'features' + os.sep + 'features.csv'\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "features_df = pd.read_csv(features_path)\n",
    "feature_names = ['assymetry', 'colours', 'dots and globules', 'compactness']\n",
    "\n",
    "# Correct the 'image_id' in features to match 'img_id' in metadata\n",
    "features_df['image_id'] = features_df['image_id'].str.replace('.png.jpg', '.png', regex=False)\n",
    "\n",
    "# Merge features with metadata on 'image_id'/'img_id'\n",
    "combined_df = features_df.merge(metadata_df[['img_id', 'diagnostic', 'patient_id']], left_on='image_id', right_on='img_id', how='left')\n",
    "\n",
    "# Check for any NaNs after the merge and handle them before proceeding.\n",
    "if combined_df.isnull().values.any():\n",
    "    raise ValueError(\"NaN values detected after merge! Check the data integrity.\")\n",
    "\n",
    "# Prepare the dataset\n",
    "X = combined_df[feature_names].to_numpy()\n",
    "y = combined_df['diagnostic'].values == 'NEV'\n",
    "patient_id = combined_df['patient_id'].values\n",
    "\n",
    "# Prepare cross-validation\n",
    "num_folds = 5\n",
    "group_kfold = GroupKFold(n_splits=num_folds)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(1),\n",
    "    KNeighborsClassifier(5),\n",
    "    make_pipeline(StandardScaler(), SVC(probability=True)),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)),\n",
    "    make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3)),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(max_iter=1000)\n",
    "]\n",
    "\n",
    "# Initialize accuracy storage\n",
    "acc_val = np.empty((num_folds, len(classifiers)))\n",
    "\n",
    "# Perform cross-validation\n",
    "for i, (train_index, val_index) in enumerate(group_kfold.split(X, y, patient_id)):\n",
    "    x_train, y_train = X[train_index], y[train_index]\n",
    "    x_val, y_val = X[val_index], y[val_index]\n",
    "    \n",
    "    for j, clf in enumerate(classifiers):\n",
    "        # Fit and predict\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        acc_val[i, j] = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Calculate average accuracy for each classifier\n",
    "average_acc = np.mean(acc_val, axis=0)\n",
    "for idx, clf in enumerate(classifiers):\n",
    "    # Print the classifier number, name, and accuracy\n",
    "    classifier_name = clf.named_steps['svc'].__class__.__name__ if 'pipeline' in str(clf) else clf.__class__.__name__\n",
    "    print(f'Classifier {idx + 1} ({classifier_name}): average accuracy={average_acc[idx]:.3f}')\n",
    "\n",
    "# Select the best classifier and train on all data\n",
    "best_index = np.argmax(average_acc)\n",
    "best_classifier = classifiers[best_index]\n",
    "best_classifier.fit(X, y)\n",
    "\n",
    "# Save the best classifier\n",
    "filename = 'best_classifier.sav'\n",
    "pickle.dump(best_classifier, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8861788617886179\n",
      "Confusion Matrix:\n",
      " [[109   0]\n",
      " [ 14   0]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the metadata and features data\n",
    "metadata_path = '..' + os.sep + 'data' + os.sep + 'metadata.csv'\n",
    "features_path = 'features/features_evaluate.csv'\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "features_df = pd.read_csv(features_path)\n",
    "feature_names = ['assymetry', 'colours', 'dots and globules', 'compactness']\n",
    "\n",
    "# Correct the 'image_id' in features to match 'img_id' in metadata\n",
    "#features_df['image_id'] = features_df['image_id'].str.replace('.png.jpg', '.png')\n",
    "\n",
    "# Merge features with metadata on 'image_id'/'img_id'\n",
    "combined_df = features_df.merge(metadata_df[['img_id', 'diagnostic', 'patient_id']], left_on='image_id', right_on='img_id', how='left')\n",
    "\n",
    "# Prepare the dataset\n",
    "X = combined_df[feature_names].to_numpy()\n",
    "y = combined_df['diagnostic'] == 'NEV'  # NEV is assumed to be the healthy class\n",
    "patient_id = combined_df['patient_id']\n",
    "\n",
    "# Load the trained classifier\n",
    "model_filename = 'best_classifier.sav'\n",
    "try:\n",
    "    with open(model_filename, 'rb') as model_file:\n",
    "        classifier = pickle.load(model_file)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the model: {e}\")\n",
    "    classifier = None\n",
    "\n",
    "# Function to classify and evaluate\n",
    "def classify_and_evaluate(X, y):\n",
    "    if classifier is None:\n",
    "        print(\"Classifier not loaded. Cannot perform classification.\")\n",
    "        return None, None\n",
    "\n",
    "    # Predict the labels\n",
    "    pred_labels = classifier.predict(X)\n",
    "\n",
    "    # Calculate accuracy and confusion matrix\n",
    "    accuracy = accuracy_score(y, pred_labels)\n",
    "    cm = confusion_matrix(y, pred_labels)\n",
    "\n",
    "    return accuracy, cm\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy, cm = classify_and_evaluate(X, y)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "118     True\n",
       "119    False\n",
       "120    False\n",
       "121    False\n",
       "122    False\n",
       "Name: diagnostic, Length: 123, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the metadata and features data\n",
    "metadata_path = '..' + os.sep + 'data' + os.sep + 'metadata.csv'\n",
    "features_path = 'features/features_evaluate.csv'\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "features_df = pd.read_csv(features_path)\n",
    "feature_names = ['assymetry', 'colours', 'dots and globules', 'compactness']\n",
    "\n",
    "# Merge features with metadata on 'image_id'/'img_id'\n",
    "combined_df = features_df.merge(metadata_df[['img_id', 'diagnostic', 'patient_id']], left_on='image_id', right_on='img_id', how='left')\n",
    "\n",
    "# Prepare the dataset\n",
    "X = combined_df[feature_names].to_numpy()\n",
    "y = combined_df['diagnostic'] == 'NEV'  # NEV is assumed to be the healthy class\n",
    "patient_id = combined_df['patient_id']\n",
    "\n",
    "# Function to load a classifier and evaluate it\n",
    "def load_and_evaluate(model_filename, X, y):\n",
    "    try:\n",
    "        with open(model_filename, 'rb') as model_file:\n",
    "            classifier = pickle.load(model_file)\n",
    "        print(f\"Loaded classifier from {model_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the model from {model_filename}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Predict the labels and calculate accuracy and confusion matrix\n",
    "    pred_labels = classifier.predict(X)\n",
    "    accuracy = accuracy_score(y, pred_labels)\n",
    "    cm = confusion_matrix(y, pred_labels)\n",
    "    \n",
    "    return accuracy, cm\n",
    "\n",
    "# List of classifier filenames\n",
    "classifier_filenames = [f'classifier_{i}.sav' for i in range(len(os.listdir(r\"C:\\Users\\tettret\\OneDrive - DFDS\\Desktop\\ITU\\Data Science Project\\Project_data_science_queen_snakes-3\\Classifier\\fyp2024\")))]\n",
    "\n",
    "# Evaluate all classifiers\n",
    "for model_filename in classifier_filenames:\n",
    "    accuracy, cm = load_and_evaluate(model_filename, X, y)\n",
    "    print(f\"Results for {model_filename}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming extract_features.py is in the same directory and has a function named extract_features\n",
    "from extract_features import extract_features\n",
    "\n",
    "# The function to classify new images. The image and mask are assumed to be loaded.\n",
    "def classify(img, mask):\n",
    "    # Resize the image etc, if you did that during training.\n",
    "    # ...\n",
    "\n",
    "    # Extract features (the same ones that you used for training).\n",
    "    # Ensure that the feature array is 2D: 1 row of features for 1 example.\n",
    "    x = extract_features(img, mask).reshape(1, -1)\n",
    "\n",
    "    # Load the trained classifier.\n",
    "    # Make sure the file name matches the one you used when saving the model.\n",
    "    classifier = pickle.load(open('best_classifier.sav', 'rb'))\n",
    "\n",
    "    # Use it on this example to predict the label AND posterior probability.\n",
    "    pred_label = classifier.predict(x)\n",
    "    pred_prob = classifier.predict_proba(x)\n",
    "\n",
    "    # Uncomment below to print the results if needed.\n",
    "    # print('Predicted label is:', pred_label)\n",
    "    # print('Predicted probability is:', pred_prob)\n",
    "    return pred_label, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image name</th>\n",
       "      <th>green circle found</th>\n",
       "      <th>dots and globules 1</th>\n",
       "      <th>dots and globules 2</th>\n",
       "      <th>dots and globules 3</th>\n",
       "      <th>img_id_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAT_101_1041_898.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_101_1041_898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAT_1063_271_448.png.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1063_271_448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAT_106_158_270.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_106_158_270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAT_1074_322_864.png.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1074_322_864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAT_1089_375_60.png.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1089_375_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>PAT_93_361_467.png.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_93_361_467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>PAT_943_1793_256.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_943_1793_256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>PAT_980_1849_295.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_980_1849_295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>PAT_983_1854_274.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_983_1854_274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>PAT_990_1860_478.png.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_990_1860_478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image name  green circle found  dots and globules 1  \\\n",
       "0    PAT_101_1041_898.png.jpg                   1                  1.0   \n",
       "1    PAT_1063_271_448.png.jpg                   0                  0.0   \n",
       "2     PAT_106_158_270.png.jpg                   1                  0.0   \n",
       "3    PAT_1074_322_864.png.jpg                   0                  0.0   \n",
       "4     PAT_1089_375_60.png.jpg                   0                  0.0   \n",
       "..                        ...                 ...                  ...   \n",
       "122    PAT_93_361_467.png.jpg                   0                  1.0   \n",
       "123  PAT_943_1793_256.png.jpg                   1                  1.0   \n",
       "124  PAT_980_1849_295.png.jpg                   1                  1.0   \n",
       "125  PAT_983_1854_274.png.jpg                   1                  1.0   \n",
       "126  PAT_990_1860_478.png.jpg                   0                  0.0   \n",
       "\n",
       "     dots and globules 2  dots and globules 3    img_id_cleaned  \n",
       "0                    1.0                  NaN  PAT_101_1041_898  \n",
       "1                    NaN                  0.0  PAT_1063_271_448  \n",
       "2                    NaN                  0.0   PAT_106_158_270  \n",
       "3                    NaN                  0.0  PAT_1074_322_864  \n",
       "4                    NaN                  0.0   PAT_1089_375_60  \n",
       "..                   ...                  ...               ...  \n",
       "122                  1.0                  NaN    PAT_93_361_467  \n",
       "123                  1.0                  NaN  PAT_943_1793_256  \n",
       "124                  1.0                  NaN  PAT_980_1849_295  \n",
       "125                  1.0                  NaN  PAT_983_1854_274  \n",
       "126                  0.0                  NaN  PAT_990_1860_478  \n",
       "\n",
       "[127 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dots['img_id_cleaned']=dots['image name'].str.split('.').str[0]\n",
    "dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image_id</th>\n",
       "      <th>Annotator ID 1</th>\n",
       "      <th>Annotator ID 2</th>\n",
       "      <th>Annotator ID 3</th>\n",
       "      <th>Asymmetry 1</th>\n",
       "      <th>Asymmetry 2</th>\n",
       "      <th>Asymmetry 3</th>\n",
       "      <th>Color 1</th>\n",
       "      <th>Color 2</th>\n",
       "      <th>Color 3</th>\n",
       "      <th>Dots and globules 1</th>\n",
       "      <th>Dots and globules 2</th>\n",
       "      <th>Dots and globules 3</th>\n",
       "      <th>img_id_cleaned</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PAT_1180_650_843_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1180_650_843</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_1180_650_843.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAT_1185_679_115_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1185_679_115</td>\n",
       "      <td>SEK</td>\n",
       "      <td>PAT_1185_679_115.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PAT_1202_722_827_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PAT_1202_722_827</td>\n",
       "      <td>SEK</td>\n",
       "      <td>PAT_1202_722_827.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PAT_1260_894_63_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1260_894_63</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_1260_894_63.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PAT_1303_1077_501_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1303_1077_501</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_1303_1077_501.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>PAT_388_4500_103_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_388_4500_103</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_388_4500_103.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>PAT_404_805_575_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_404_805_575</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_404_805_575.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>PAT_406_1542_754_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_406_1542_754</td>\n",
       "      <td>BCC</td>\n",
       "      <td>PAT_406_1542_754.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>PAT_406_808_560_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_406_808_560</td>\n",
       "      <td>BCC</td>\n",
       "      <td>PAT_406_808_560.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>PAT_409_2614_24_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_409_2614_24</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_409_2614_24.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                        Image_id Annotator ID 1 Annotator ID 2  \\\n",
       "0             0   PAT_1180_650_843_mask.png.jpg             q1            NaN   \n",
       "1             1   PAT_1185_679_115_mask.png.jpg             q1            NaN   \n",
       "2             2   PAT_1202_722_827_mask.png.jpg             q1            NaN   \n",
       "3             3    PAT_1260_894_63_mask.png.jpg             q1            NaN   \n",
       "4             4  PAT_1303_1077_501_mask.png.jpg             q1            NaN   \n",
       "..          ...                             ...            ...            ...   \n",
       "122         122   PAT_388_4500_103_mask.png.jpg             q3             q2   \n",
       "123         123    PAT_404_805_575_mask.png.jpg             q3             q2   \n",
       "124         124   PAT_406_1542_754_mask.png.jpg             q3             q2   \n",
       "125         125    PAT_406_808_560_mask.png.jpg             q3             q2   \n",
       "126         126    PAT_409_2614_24_mask.png.jpg             q3             q2   \n",
       "\n",
       "    Annotator ID 3  Asymmetry 1  Asymmetry 2  Asymmetry 3  Color 1  Color 2  \\\n",
       "0               q4          2.0          NaN          0.0      3.0      NaN   \n",
       "1               q4          1.0          NaN          1.0      3.0      NaN   \n",
       "2               q4          2.0          NaN          1.0      2.0      NaN   \n",
       "3               q4          2.0          NaN          1.0      2.0      NaN   \n",
       "4               q4          2.0          NaN          0.0      3.0      NaN   \n",
       "..             ...          ...          ...          ...      ...      ...   \n",
       "122            NaN          2.0          2.0          NaN      2.0      2.0   \n",
       "123            NaN          1.0          1.0          NaN      2.0      3.0   \n",
       "124            NaN          0.0          0.0          NaN      4.0      4.0   \n",
       "125            NaN          1.0          0.0          NaN      3.0      4.0   \n",
       "126            NaN          1.0          2.0          NaN      2.0      2.0   \n",
       "\n",
       "     Color 3  Dots and globules 1  Dots and globules 2  Dots and globules 3  \\\n",
       "0        1.0                  0.0                  NaN                  0.0   \n",
       "1        2.0                  0.0                  NaN                  0.0   \n",
       "2        2.0                  1.0                  NaN                  1.0   \n",
       "3        2.0                  0.0                  NaN                  0.0   \n",
       "4        3.0                  0.0                  NaN                  0.0   \n",
       "..       ...                  ...                  ...                  ...   \n",
       "122      NaN                  0.0                  0.0                  NaN   \n",
       "123      NaN                  1.0                  1.0                  NaN   \n",
       "124      NaN                  1.0                  1.0                  NaN   \n",
       "125      NaN                  1.0                  1.0                  NaN   \n",
       "126      NaN                  0.0                  0.0                  NaN   \n",
       "\n",
       "        img_id_cleaned diagnostic                 img_id  \n",
       "0     PAT_1180_650_843        ACK   PAT_1180_650_843.png  \n",
       "1     PAT_1185_679_115        SEK   PAT_1185_679_115.png  \n",
       "2     PAT_1202_722_827        SEK   PAT_1202_722_827.png  \n",
       "3      PAT_1260_894_63        ACK    PAT_1260_894_63.png  \n",
       "4    PAT_1303_1077_501        ACK  PAT_1303_1077_501.png  \n",
       "..                 ...        ...                    ...  \n",
       "122   PAT_388_4500_103        ACK   PAT_388_4500_103.png  \n",
       "123    PAT_404_805_575        ACK    PAT_404_805_575.png  \n",
       "124   PAT_406_1542_754        BCC   PAT_406_1542_754.png  \n",
       "125    PAT_406_808_560        BCC    PAT_406_808_560.png  \n",
       "126    PAT_409_2614_24        ACK    PAT_409_2614_24.png  \n",
       "\n",
       "[127 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image_id</th>\n",
       "      <th>Annotator ID 1</th>\n",
       "      <th>Annotator ID 2</th>\n",
       "      <th>Annotator ID 3</th>\n",
       "      <th>Asymmetry 1</th>\n",
       "      <th>Asymmetry 2</th>\n",
       "      <th>Asymmetry 3</th>\n",
       "      <th>Color 1</th>\n",
       "      <th>Color 2</th>\n",
       "      <th>...</th>\n",
       "      <th>Dots and globules 2</th>\n",
       "      <th>Dots and globules 3</th>\n",
       "      <th>img_id_cleaned</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>img_id</th>\n",
       "      <th>image name</th>\n",
       "      <th>green circle found</th>\n",
       "      <th>dots and globules 1</th>\n",
       "      <th>dots and globules 2</th>\n",
       "      <th>dots and globules 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PAT_1180_650_843_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1180_650_843</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_1180_650_843.png</td>\n",
       "      <td>PAT_1180_650_843.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAT_1185_679_115_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1185_679_115</td>\n",
       "      <td>SEK</td>\n",
       "      <td>PAT_1185_679_115.png</td>\n",
       "      <td>PAT_1185_679_115.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PAT_1202_722_827_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PAT_1202_722_827</td>\n",
       "      <td>SEK</td>\n",
       "      <td>PAT_1202_722_827.png</td>\n",
       "      <td>PAT_1202_722_827.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PAT_1260_894_63_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1260_894_63</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_1260_894_63.png</td>\n",
       "      <td>PAT_1260_894_63.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PAT_1303_1077_501_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1303_1077_501</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_1303_1077_501.png</td>\n",
       "      <td>PAT_1303_1077_501.png.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>PAT_388_4500_103_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_388_4500_103</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_388_4500_103.png</td>\n",
       "      <td>PAT_388_4500_103.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>PAT_404_805_575_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_404_805_575</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_404_805_575.png</td>\n",
       "      <td>PAT_404_805_575.png.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>PAT_406_1542_754_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_406_1542_754</td>\n",
       "      <td>BCC</td>\n",
       "      <td>PAT_406_1542_754.png</td>\n",
       "      <td>PAT_406_1542_754.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>PAT_406_808_560_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_406_808_560</td>\n",
       "      <td>BCC</td>\n",
       "      <td>PAT_406_808_560.png</td>\n",
       "      <td>PAT_406_808_560.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>PAT_409_2614_24_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_409_2614_24</td>\n",
       "      <td>ACK</td>\n",
       "      <td>PAT_409_2614_24.png</td>\n",
       "      <td>PAT_409_2614_24.png.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                        Image_id Annotator ID 1 Annotator ID 2  \\\n",
       "0             0   PAT_1180_650_843_mask.png.jpg             q1            NaN   \n",
       "1             1   PAT_1185_679_115_mask.png.jpg             q1            NaN   \n",
       "2             2   PAT_1202_722_827_mask.png.jpg             q1            NaN   \n",
       "3             3    PAT_1260_894_63_mask.png.jpg             q1            NaN   \n",
       "4             4  PAT_1303_1077_501_mask.png.jpg             q1            NaN   \n",
       "..          ...                             ...            ...            ...   \n",
       "122         122   PAT_388_4500_103_mask.png.jpg             q3             q2   \n",
       "123         123    PAT_404_805_575_mask.png.jpg             q3             q2   \n",
       "124         124   PAT_406_1542_754_mask.png.jpg             q3             q2   \n",
       "125         125    PAT_406_808_560_mask.png.jpg             q3             q2   \n",
       "126         126    PAT_409_2614_24_mask.png.jpg             q3             q2   \n",
       "\n",
       "    Annotator ID 3  Asymmetry 1  Asymmetry 2  Asymmetry 3  Color 1  Color 2  \\\n",
       "0               q4          2.0          NaN          0.0      3.0      NaN   \n",
       "1               q4          1.0          NaN          1.0      3.0      NaN   \n",
       "2               q4          2.0          NaN          1.0      2.0      NaN   \n",
       "3               q4          2.0          NaN          1.0      2.0      NaN   \n",
       "4               q4          2.0          NaN          0.0      3.0      NaN   \n",
       "..             ...          ...          ...          ...      ...      ...   \n",
       "122            NaN          2.0          2.0          NaN      2.0      2.0   \n",
       "123            NaN          1.0          1.0          NaN      2.0      3.0   \n",
       "124            NaN          0.0          0.0          NaN      4.0      4.0   \n",
       "125            NaN          1.0          0.0          NaN      3.0      4.0   \n",
       "126            NaN          1.0          2.0          NaN      2.0      2.0   \n",
       "\n",
       "     ...  Dots and globules 2  Dots and globules 3     img_id_cleaned  \\\n",
       "0    ...                  NaN                  0.0   PAT_1180_650_843   \n",
       "1    ...                  NaN                  0.0   PAT_1185_679_115   \n",
       "2    ...                  NaN                  1.0   PAT_1202_722_827   \n",
       "3    ...                  NaN                  0.0    PAT_1260_894_63   \n",
       "4    ...                  NaN                  0.0  PAT_1303_1077_501   \n",
       "..   ...                  ...                  ...                ...   \n",
       "122  ...                  0.0                  NaN   PAT_388_4500_103   \n",
       "123  ...                  1.0                  NaN    PAT_404_805_575   \n",
       "124  ...                  1.0                  NaN   PAT_406_1542_754   \n",
       "125  ...                  1.0                  NaN    PAT_406_808_560   \n",
       "126  ...                  0.0                  NaN    PAT_409_2614_24   \n",
       "\n",
       "     diagnostic                 img_id                 image name  \\\n",
       "0           ACK   PAT_1180_650_843.png   PAT_1180_650_843.png.jpg   \n",
       "1           SEK   PAT_1185_679_115.png   PAT_1185_679_115.png.jpg   \n",
       "2           SEK   PAT_1202_722_827.png   PAT_1202_722_827.png.jpg   \n",
       "3           ACK    PAT_1260_894_63.png    PAT_1260_894_63.png.jpg   \n",
       "4           ACK  PAT_1303_1077_501.png  PAT_1303_1077_501.png.jpg   \n",
       "..          ...                    ...                        ...   \n",
       "122         ACK   PAT_388_4500_103.png   PAT_388_4500_103.png.jpg   \n",
       "123         ACK    PAT_404_805_575.png    PAT_404_805_575.png.jpg   \n",
       "124         BCC   PAT_406_1542_754.png   PAT_406_1542_754.png.jpg   \n",
       "125         BCC    PAT_406_808_560.png    PAT_406_808_560.png.jpg   \n",
       "126         ACK    PAT_409_2614_24.png    PAT_409_2614_24.png.jpg   \n",
       "\n",
       "    green circle found dots and globules 1  dots and globules 2  \\\n",
       "0                    1                 0.0                  NaN   \n",
       "1                    1                 1.0                  NaN   \n",
       "2                    1                 1.0                  NaN   \n",
       "3                    1                 0.0                  NaN   \n",
       "4                    0                 0.0                  NaN   \n",
       "..                 ...                 ...                  ...   \n",
       "122                  1                 0.0                  0.0   \n",
       "123                  0                 0.0                  0.0   \n",
       "124                  1                 1.0                  1.0   \n",
       "125                  1                 1.0                  1.0   \n",
       "126                  1                 0.0                  0.0   \n",
       "\n",
       "     dots and globules 3  \n",
       "0                    0.0  \n",
       "1                    1.0  \n",
       "2                    1.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "..                   ...  \n",
       "122                  NaN  \n",
       "123                  NaN  \n",
       "124                  NaN  \n",
       "125                  NaN  \n",
       "126                  NaN  \n",
       "\n",
       "[127 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_metadata_dots=pd.merge(annotations_metadata,dots, on=\"img_id_cleaned\", how=\"left\")\n",
    "annotations_metadata_dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image_id</th>\n",
       "      <th>Annotator ID 1</th>\n",
       "      <th>Annotator ID 2</th>\n",
       "      <th>Annotator ID 3</th>\n",
       "      <th>Asymmetry 1</th>\n",
       "      <th>Asymmetry 2</th>\n",
       "      <th>Asymmetry 3</th>\n",
       "      <th>Color 1</th>\n",
       "      <th>Color 2</th>\n",
       "      <th>Color 3</th>\n",
       "      <th>Dots and globules 1</th>\n",
       "      <th>Dots and globules 2</th>\n",
       "      <th>Dots and globules 3</th>\n",
       "      <th>img_id_cleaned</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PAT_1180_650_843_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1180_650_843_mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAT_1185_679_115_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1185_679_115_mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PAT_1202_722_827_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PAT_1202_722_827_mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PAT_1260_894_63_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1260_894_63_mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PAT_1303_1077_501_mask.png.jpg</td>\n",
       "      <td>q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PAT_1303_1077_501_mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>PAT_388_4500_103_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_388_4500_103_mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>PAT_404_805_575_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_404_805_575_mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>PAT_406_1542_754_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_406_1542_754_mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>PAT_406_808_560_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_406_808_560_mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>PAT_409_2614_24_mask.png.jpg</td>\n",
       "      <td>q3</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAT_409_2614_24_mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                        Image_id Annotator ID 1 Annotator ID 2  \\\n",
       "0             0   PAT_1180_650_843_mask.png.jpg             q1            NaN   \n",
       "1             1   PAT_1185_679_115_mask.png.jpg             q1            NaN   \n",
       "2             2   PAT_1202_722_827_mask.png.jpg             q1            NaN   \n",
       "3             3    PAT_1260_894_63_mask.png.jpg             q1            NaN   \n",
       "4             4  PAT_1303_1077_501_mask.png.jpg             q1            NaN   \n",
       "..          ...                             ...            ...            ...   \n",
       "122         122   PAT_388_4500_103_mask.png.jpg             q3             q2   \n",
       "123         123    PAT_404_805_575_mask.png.jpg             q3             q2   \n",
       "124         124   PAT_406_1542_754_mask.png.jpg             q3             q2   \n",
       "125         125    PAT_406_808_560_mask.png.jpg             q3             q2   \n",
       "126         126    PAT_409_2614_24_mask.png.jpg             q3             q2   \n",
       "\n",
       "    Annotator ID 3  Asymmetry 1  Asymmetry 2  Asymmetry 3  Color 1  Color 2  \\\n",
       "0               q4          2.0          NaN          0.0      3.0      NaN   \n",
       "1               q4          1.0          NaN          1.0      3.0      NaN   \n",
       "2               q4          2.0          NaN          1.0      2.0      NaN   \n",
       "3               q4          2.0          NaN          1.0      2.0      NaN   \n",
       "4               q4          2.0          NaN          0.0      3.0      NaN   \n",
       "..             ...          ...          ...          ...      ...      ...   \n",
       "122            NaN          2.0          2.0          NaN      2.0      2.0   \n",
       "123            NaN          1.0          1.0          NaN      2.0      3.0   \n",
       "124            NaN          0.0          0.0          NaN      4.0      4.0   \n",
       "125            NaN          1.0          0.0          NaN      3.0      4.0   \n",
       "126            NaN          1.0          2.0          NaN      2.0      2.0   \n",
       "\n",
       "     Color 3  Dots and globules 1  Dots and globules 2  Dots and globules 3  \\\n",
       "0        1.0                  0.0                  NaN                  0.0   \n",
       "1        2.0                  0.0                  NaN                  0.0   \n",
       "2        2.0                  1.0                  NaN                  1.0   \n",
       "3        2.0                  0.0                  NaN                  0.0   \n",
       "4        3.0                  0.0                  NaN                  0.0   \n",
       "..       ...                  ...                  ...                  ...   \n",
       "122      NaN                  0.0                  0.0                  NaN   \n",
       "123      NaN                  1.0                  1.0                  NaN   \n",
       "124      NaN                  1.0                  1.0                  NaN   \n",
       "125      NaN                  1.0                  1.0                  NaN   \n",
       "126      NaN                  0.0                  0.0                  NaN   \n",
       "\n",
       "             img_id_cleaned diagnostic img_id  \n",
       "0     PAT_1180_650_843_mask        NaN    NaN  \n",
       "1     PAT_1185_679_115_mask        NaN    NaN  \n",
       "2     PAT_1202_722_827_mask        NaN    NaN  \n",
       "3      PAT_1260_894_63_mask        NaN    NaN  \n",
       "4    PAT_1303_1077_501_mask        NaN    NaN  \n",
       "..                      ...        ...    ...  \n",
       "122   PAT_388_4500_103_mask        NaN    NaN  \n",
       "123    PAT_404_805_575_mask        NaN    NaN  \n",
       "124   PAT_406_1542_754_mask        NaN    NaN  \n",
       "125    PAT_406_808_560_mask        NaN    NaN  \n",
       "126    PAT_409_2614_24_mask        NaN    NaN  \n",
       "\n",
       "[127 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "metadata_filename='..' + os.sep + 'data' + os.sep +'metadata.csv'\n",
    "metadata=pd.read_csv(metadata_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'lesion_id', 'smoke', 'drink', 'background_father',\n",
       "       'background_mother', 'age', 'pesticide', 'gender',\n",
       "       'skin_cancer_history', 'cancer_history', 'has_piped_water',\n",
       "       'has_sewage_system', 'fitspatrick', 'region', 'diameter_1',\n",
       "       'diameter_2', 'diagnostic', 'itch', 'grew', 'hurt', 'changed', 'bleed',\n",
       "       'elevation', 'img_id', 'biopsed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
